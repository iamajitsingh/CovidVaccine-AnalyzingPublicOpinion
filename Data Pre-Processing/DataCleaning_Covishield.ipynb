{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CovishieldCleaning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_eNTe0rSbPl"
      },
      "source": [
        "# Import PyDrive and associated libraries\n",
        "# This only needs to be done once per notebook\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "# This only needs to be done once per notebook\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqUKo_FhS-mq"
      },
      "source": [
        "# Download a file based on its file ID.\n",
        "\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '18f-PcR4RTj09Hxo8x55EHN_XUjbHd-_J' # Check your own ID in GDrive\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "# Save file in Colab memory\n",
        "downloaded.GetContentFile('tweets1.csv')  \n",
        "\n",
        "# Rest of the December files\n",
        "file_id = '1u_Ks7aqAYk9TZA7sUOfN-KxqClY6laZ_' \n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('tweets2.csv')  \n",
        "file_id = '1vSGqdNAy7Ong_4zz7u6wYWk-FZh5-oI9' \n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('tweets3.csv')  \n",
        "file_id = '1oY3-xV-wQDcSkM0t30DwI7vgkdkn1Y4N' \n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('tweets4.csv')  \n",
        "file_id = '1MYAPeIy0JPn2TX1vTujm6hWb_jVBByTK' \n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('tweets5.csv')  \n",
        "file_id = '1EOs3CL34wGApAgc_bHQVkCFJ4cmUUB3j' \n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('tweets6.csv')  \n",
        "file_id = '11uobtM5Eu3g4i91ERVNnld_QT1eeIlsJ' \n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('tweets7.csv')  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCqwNwzkT6O1"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc4SzXzXURC3",
        "outputId": "bac54fd2-bc26-48bf-8580-416d8903f2f9"
      },
      "source": [
        "pip install contractions emoji"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.0.52-py2.py3-none-any.whl (7.2 kB)\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.6.0.tar.gz (168 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 168 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.0-py3-none-any.whl (284 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 284 kB 38.6 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.2.tar.gz (321 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 321 kB 48.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji, pyahocorasick\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.0-py3-none-any.whl size=168256 sha256=cbd1df8df6c229a4fc7b4e838723d57c95414949aa8ce2bbefe0bdf88a4fc10e\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/d7/74/c720aaf345a042b0c2d74361873258c5e8649b7f11b2ccce49\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85456 sha256=1d81a5d1c84109886adba941ef4d68dd4027ecf82eb00846da0dc729e87a360d\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/19/a6/8f363d9939162782bb8439d886469756271abc01f76fbd790f\n",
            "Successfully built emoji pyahocorasick\n",
            "Installing collected packages: pyahocorasick, anyascii, textsearch, emoji, contractions\n",
            "Successfully installed anyascii-0.3.0 contractions-0.0.52 emoji-1.6.0 pyahocorasick-1.4.2 textsearch-0.0.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHeE-I36UXG2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import re, contractions, emoji\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "def clean_date(date_obj):\n",
        "  for x in range(0, len(date_obj)):\n",
        "    if date_obj[x] == \" \":\n",
        "      break\n",
        "  date_obj = date_obj[:x]\n",
        "  return date_obj\n",
        "\n",
        "def process_tweet(tweet):\n",
        "  ## Twitter Features\n",
        "    # replace retweet\n",
        "  tweet = re.sub('RT\\s+', \"\", tweet )\n",
        "    # replace user tag\n",
        "  tweet = re.sub('\\B@\\w+', \"\", tweet)\n",
        "    # replace url\n",
        "  tweet = re.sub('(http|https):\\/\\/\\S+', \"\", tweet)\n",
        "    # replace hashtag\n",
        "  tweet = re.sub('#+', \"\", tweet)\n",
        "\n",
        "  ## Word Features\n",
        "    # lower case\n",
        "  tweet = tweet.lower()\n",
        "    # replace contractions\n",
        "  tweet = contractions.fix(tweet)\n",
        "    # replace punctuation repetition\n",
        "  tweet = re.sub(r'[\\?\\.\\!]+(?=[\\?\\.\\!])', \"\", tweet)\n",
        "    # replace word repetition\n",
        "  tweet = re.sub(r'(.)\\1+', r'\\1\\1', tweet)\n",
        "    # replace emojis\n",
        "  tweet = emoji.demojize(tweet)\n",
        "\n",
        "  return tweet\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ-ZRsX5T_Ay"
      },
      "source": [
        "df1 = pd.read_csv('tweets1.csv',\n",
        "                 lineterminator='\\n')\n",
        "df1 = df1[df1[\"Language\\r\"]==\"en\\r\"].drop(['Unnamed: 0', 'Tweet Id', 'Language\\r'],axis=1)\n",
        "df1[\"Datetime\"] = df1[\"Datetime\"].apply(clean_date)\n",
        "df1[\"Clean Text\"] = df1[\"Text\"].apply(process_tweet)\n",
        "df1['Clean Text']= df1['Clean Text'].str.replace('[^\\w\\s]','')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gTCJmKRUAxS"
      },
      "source": [
        "df2 = pd.read_csv('tweets2.csv',\n",
        "                 lineterminator='\\n')\n",
        "df2 = df2[df2[\"Language\\r\"]==\"en\\r\"].drop(['Unnamed: 0', 'Tweet Id', 'Language\\r'],axis=1)\n",
        "df2[\"Datetime\"] = df2[\"Datetime\"].apply(clean_date)\n",
        "df2[\"Clean Text\"] = df2[\"Text\"].apply(process_tweet)\n",
        "df2['Clean Text']= df2['Clean Text'].str.replace('[^\\w\\s]','')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfurX1mvUFKF"
      },
      "source": [
        "df3 = pd.read_csv('tweets3.csv',\n",
        "                 lineterminator='\\n')\n",
        "df3 = df3[df3[\"Language\\r\"]==\"en\\r\"].drop(['Unnamed: 0', 'Tweet Id', 'Language\\r'],axis=1)\n",
        "df3[\"Datetime\"] = df3[\"Datetime\"].apply(clean_date)\n",
        "df3[\"Clean Text\"] = df3[\"Text\"].apply(process_tweet)\n",
        "df3['Clean Text']= df3['Clean Text'].str.replace('[^\\w\\s]','')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IAdTOcYVEpC"
      },
      "source": [
        "df4 = pd.read_csv('tweets4.csv',\n",
        "                 lineterminator='\\n')\n",
        "df4 = df4[df4[\"Language\\r\"]==\"en\\r\"].drop(['Unnamed: 0', 'Tweet Id', 'Language\\r'],axis=1)\n",
        "df4[\"Datetime\"] = df4[\"Datetime\"].apply(clean_date)\n",
        "df4[\"Clean Text\"] = df4[\"Text\"].apply(process_tweet)\n",
        "df4['Clean Text']= df4['Clean Text'].str.replace('[^\\w\\s]','')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz7GIR7WVLfX"
      },
      "source": [
        "df5 = pd.read_csv('tweets5.csv',\n",
        "                 lineterminator='\\n')\n",
        "df5 = df5[df5[\"Language\\r\"]==\"en\\r\"].drop(['Unnamed: 0', 'Tweet Id', 'Language\\r'],axis=1)\n",
        "df5[\"Datetime\"] = df5[\"Datetime\"].apply(clean_date)\n",
        "df5[\"Clean Text\"] = df5[\"Text\"].apply(process_tweet)\n",
        "df5['Clean Text']= df5['Clean Text'].str.replace('[^\\w\\s]','')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR3IvT2FVR_J"
      },
      "source": [
        "df6 = pd.read_csv('tweets6.csv',\n",
        "                 lineterminator='\\n')\n",
        "df6 = df6[df6[\"Language\\r\"]==\"en\\r\"].drop(['Unnamed: 0', 'Tweet Id', 'Language\\r'],axis=1)\n",
        "df6[\"Datetime\"] = df6[\"Datetime\"].apply(clean_date)\n",
        "df6[\"Clean Text\"] = df6[\"Text\"].apply(process_tweet)\n",
        "df6['Clean Text']= df6['Clean Text'].str.replace('[^\\w\\s]','')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yypNNwJVW6w"
      },
      "source": [
        "df7 = pd.read_csv('tweets7.csv',\n",
        "                 lineterminator='\\n')\n",
        "df7 = df7[df7[\"Language\\r\"]==\"en\\r\"].drop(['Unnamed: 0', 'Tweet Id', 'Language\\r'],axis=1)\n",
        "df7[\"Datetime\"] = df7[\"Datetime\"].apply(clean_date)\n",
        "df7[\"Clean Text\"] = df7[\"Text\"].apply(process_tweet)\n",
        "df7['Clean Text']= df7['Clean Text'].str.replace('[^\\w\\s]','')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "1csHeeUMVdFa",
        "outputId": "1670023c-3c7b-4db0-b437-44eed4a597c4"
      },
      "source": [
        "df_cov = pd.concat([df1, df2, df3, df4, df5, df6, df7])\n",
        "df_cov = df_cov.sort_values(by=['Datetime'])\n",
        "df_cov.drop_duplicates(subset =[\"Datetime\", \"Text\", \"Like Count\", \"Username\"], keep = False, inplace = True)\n",
        "df_cov = df_cov.reset_index()\n",
        "del df_cov['index']\n",
        "df_cov"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Datetime</th>\n",
              "      <th>Text</th>\n",
              "      <th>Username</th>\n",
              "      <th>Like Count</th>\n",
              "      <th>Display Name</th>\n",
              "      <th>Clean Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-12-01</td>\n",
              "      <td>Clarifying on the Chennai case, the SII claime...</td>\n",
              "      <td>DeccanHerald</td>\n",
              "      <td>6</td>\n",
              "      <td>Deccan Herald</td>\n",
              "      <td>clarifying on the chennai case the sii claimed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-12-01</td>\n",
              "      <td>‚ÄúSuch lack of transparency is neither conduciv...</td>\n",
              "      <td>QuintFit</td>\n",
              "      <td>12</td>\n",
              "      <td>Quint Fit</td>\n",
              "      <td>such lack of transparency is neither conducive...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-12-01</td>\n",
              "      <td>Covishield vaccine safe and immunogenic, incid...</td>\n",
              "      <td>While_NEWS</td>\n",
              "      <td>0</td>\n",
              "      <td>While NEWS</td>\n",
              "      <td>covishield vaccine safe and immunogenic incide...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-12-01</td>\n",
              "      <td>‚ö°Ô∏è ‚ÄúSerum Institute claims that its COVID vacc...</td>\n",
              "      <td>BiIndia</td>\n",
              "      <td>27</td>\n",
              "      <td>Business Insider IndiaüáÆüá≥</td>\n",
              "      <td>high_voltage serum institute claims that its c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-12-01</td>\n",
              "      <td>Serum Institute denies side effects claim, say...</td>\n",
              "      <td>jimiless</td>\n",
              "      <td>0</td>\n",
              "      <td>joseph m</td>\n",
              "      <td>serum institute denies side effects claim says...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371576</th>\n",
              "      <td>2021-09-30</td>\n",
              "      <td>18-44 #RURAL #Bengaluru #CovidVaccine Availabi...</td>\n",
              "      <td>vaxblr</td>\n",
              "      <td>0</td>\n",
              "      <td>VaxBLR</td>\n",
              "      <td>1844 rural bengaluru covidvaccine availability...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371577</th>\n",
              "      <td>2021-09-30</td>\n",
              "      <td>@KTRTRS @MinisterKTR people at district king k...</td>\n",
              "      <td>iamvicky1308</td>\n",
              "      <td>0</td>\n",
              "      <td>Vikas Gupta</td>\n",
              "      <td>people at district king koti hospital waitin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371578</th>\n",
              "      <td>2021-09-30</td>\n",
              "      <td>Mumbai: List of govt vaccination centres admin...</td>\n",
              "      <td>TOICitiesNews</td>\n",
              "      <td>0</td>\n",
              "      <td>TOI Cities</td>\n",
              "      <td>mumbai list of govt vaccination centres admini...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371579</th>\n",
              "      <td>2021-09-30</td>\n",
              "      <td>45+ #BBMP #Bengaluru #CovidVaccine Availabilit...</td>\n",
              "      <td>vaxblr</td>\n",
              "      <td>0</td>\n",
              "      <td>VaxBLR</td>\n",
              "      <td>45 bbmp bengaluru covidvaccine availability fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371580</th>\n",
              "      <td>2021-09-30</td>\n",
              "      <td>Mumbai: List of govt vaccination centres admin...</td>\n",
              "      <td>TOIMumbai</td>\n",
              "      <td>19</td>\n",
              "      <td>TOI Mumbai</td>\n",
              "      <td>mumbai list of govt vaccination centres admini...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>371581 rows √ó 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Datetime  ...                                         Clean Text\n",
              "0       2020-12-01  ...  clarifying on the chennai case the sii claimed...\n",
              "1       2020-12-01  ...  such lack of transparency is neither conducive...\n",
              "2       2020-12-01  ...  covishield vaccine safe and immunogenic incide...\n",
              "3       2020-12-01  ...  high_voltage serum institute claims that its c...\n",
              "4       2020-12-01  ...  serum institute denies side effects claim says...\n",
              "...            ...  ...                                                ...\n",
              "371576  2021-09-30  ...  1844 rural bengaluru covidvaccine availability...\n",
              "371577  2021-09-30  ...    people at district king koti hospital waitin...\n",
              "371578  2021-09-30  ...  mumbai list of govt vaccination centres admini...\n",
              "371579  2021-09-30  ...  45 bbmp bengaluru covidvaccine availability fo...\n",
              "371580  2021-09-30  ...  mumbai list of govt vaccination centres admini...\n",
              "\n",
              "[371581 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-Rd5sOpWPL7"
      },
      "source": [
        "df_cov.to_csv('cov.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1D4YOJVgPmw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}